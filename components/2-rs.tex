\section{Recommendation systems} \label{section:rs}
	Recommendation systems leverage data and algorithms to offer personalized suggestions to users, enhancing their decision-making in various domains. These systems use collaborative filtering, content-based filtering, and hybrid approaches, facilitating tailored content, product, or service recommendations, ultimately improving user engagement and satisfaction in diverse applications, from e-commerce to content streaming.

	Clothing and fashion recommendation systems present a unique and intricate challenge compared to general recommendation systems. They must consider not only user preferences but also the highly subjective and context-dependent nature of fashion. Recommending apparel necessitates understanding intricate details like style, fit, and individual tastes, which can evolve over time. The ever-changing fashion trends further complicate the task. Fashion items often involve combinations, making recommendations more complex.

	Moreover, the emotional aspect of fashion and the need for users to express their individuality make it challenging to predict preferences accurately. These systems must encompass visual recognition, trend analysis, and personalization, making fashion recommendation systems not only distinct but also more demanding to develop with precision.

	\subsection{Goals of recommendation systems}
		Studying the literature for clothing and fashion recommendation systems reveals the following goals:

		\begin{enumerate}
			\item \textbf{Outfit recommendation:} This is similar to the goal of generic recommendation systems as it aims to recommend garments or outfits based on the user's preferences (e.g., complex color patterns, or specific fabrics and textures), body attributes like color and shape, current trends, and custom contexts specified by the user (e.g., outfit for a formal party) \cite{DBLP:conf/sigir/LiW0CXC20, 9156794, 8932738, DBLP:conf/mm/HidayatiHCHFC18, DBLP:journals/tmm/ZhangJGZZLT17, DBLP:conf/waim/ShaWZFZY16}.
			
			\item \textbf{Outfit generation:} This goal is, given a clothing item (e.g., a shirt), find the best garment (e.g., a tie) or outfit (e.g., from pants, skirts, ties, shoes, or hats) that is compatible with the given item. A special case of this goal is pair generation, where one item is the query and a suitable pairing item is needed. This is usually done for top and bottom items \cite{9156535, 9893574, DBLP:conf/kdd/ChenHXGGSLPZZ19}.
			
			\item \textbf{Outfit completion:} This is when most of the outfit is in place, and the task is to complete the outfit's missing items (e.g., what shoes to wear with this outfit?). Also known as fill-in-the-blank (FITB) test \cite{9857004, DBLP:journals/corr/abs-2005-06584, DBLP:conf/mm/SongHLCXN19}.
			
			\item \textbf{Outfit compatibility evaluation:} Also an implicit goal for other tasks, this aims to score an outfit based on how compatible its constituent elements are. This can be used as a metric to rank outfits (e.g., does the red shirt go well with the black skirt and black socks or is the white shirt better?) \cite{DBLP:journals/eswa/MoZPW23, 10049142, DBLP:journals/eswa/BalimO23,9775146, DBLP:conf/iccvw/KimSMSSP21, DBLP:journals/ijon/SunHWZP20, DBLP:conf/sigir/DongWSDN20, DBLP:conf/www/YinL0019, DBLP:conf/aaai/YangMLWC19}.

			\item \textbf{Explainable recommendation:} An explanation clarifies why something was recommended to the user. Explanations are more transparent than black-box recommendations and improve the user experience in a variety of ways. They enhance user trust and understanding, lead to error detection and correction, mitigate bias and promote fairness, and increase user engagement. In recent years, more work has been done on explainable fashion recommendation \cite{DBLP:journals/tomccap/YangSFWDN21, DBLP:journals/www/LiCH21, 9522737, DBLP:journals/tkde/LinRCRMR20, DBLP:conf/wacv/TangsengO20, DBLP:conf/ijcai/HouWCLZL19, DBLP:conf/sigir/ChenCXZ0QZ19}.
		\end{enumerate}
	
		\newcommand{\checkif}[1]{
			\ifthenelse{\equal{#1}{Y}}{\checkmark}{}
		}
		\newcommand{\rsrow}[8]{
			\citeauthor{#1} \cite{#1} & \citeyear{#1} & #2 &
			\checkif{#3} &
			\checkif{#4} &
			\checkif{#5} &
			\checkif{#6} &
			\checkif{#7} &
			\checkif{#8}
			\\
		}
		
		\begin{table*}
			\caption{Recommendation Systems}
			\label{table:rs}
			\begin{tabularx}{\textwidth}{
				p{2.8cm} p{0.5cm} X |
				>{\centering\arraybackslash}p{0.6cm} 
				>{\centering\arraybackslash}p{1.4cm} |
				>{\centering\arraybackslash}p{0.75cm}
				>{\centering\arraybackslash}p{0.6cm}
				>{\centering\arraybackslash}p{1.3cm} |
				>{\centering\arraybackslash}p{1.5cm}
			}
				\toprule
					\textbf{Authors} &
					\textbf{Year} &
					\textbf{Technique(s)} &
					\multicolumn{2}{c|}{\textbf{User Inputs}} &
					\multicolumn{3}{c|}{\textbf{Outputs}} &
					\textbf{Personalized}
					\\
					& & &
					Body Attr. & Interactions\footnotemark[1] &
					Compat. & Outfit Gen. & Explainable
					& \\
				\midrule
					\rsrow{DBLP:journals/eswa/MoZPW23}{
						Transformer $\rightarrow$ Transformer
					}{Y}{}{Y}{Y}{}{Y}
					\rsrow{10049142}{
						Contextual Attention Network
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:journals/eswa/BalimO23}{
						CNN $\rightarrow$ LSTM + Transformer
					}{}{Y}{Y}{}{Y}{}
					\rsrow{9857004}{
						Triplet Network
					}{}{}{Y}{Y}{}{}
					\rsrow{9893574}{
						Bi-LSTM, GAN
					}{}{}{Y}{Y}{}{}
					\rsrow{9775146}{
						Bi-LSTM
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:journals/tomccap/YangSFWDN21}{
						Representation Learning
					}{}{Y}{Y}{Y}{Y}{}
					\rsrow{DBLP:conf/iccvw/KimSMSSP21}{
						CNN + Projection Head
					}{}{}{Y}{Y}{}{}
					\rsrow{9156535}{
						CNN + Triplet Network
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:conf/sigir/DongWSDN20}{
						Bi-LSTM
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:journals/ijon/SunHWZP20}{
						LSTM + Triplet Network
					}{}{}{Y}{Y}{}{}
					\rsrow{9156794}{
						CNN + SMPL Est. $\rightarrow$ Joint Embedding
					}{Y}{}{Y}{Y}{Y}{Y}
					\rsrow{DBLP:conf/sigir/LiW0CXC20}{
						Heirarchical Graph Network
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:journals/corr/abs-2005-06584}{
						Relational Network + VSE
					}{}{}{Y}{Y}{}{}
					\rsrow{DBLP:conf/aaai/YangMLWC19}{
						Unified Embedding Space
					}{}{}{Y}{}{}{}
					\rsrow{DBLP:conf/kdd/ChenHXGGSLPZZ19}{
						BPR + CNN $\rightarrow$ Transformer
					}{}{Y}{Y}{Y}{}{Y}
					\rsrow{DBLP:conf/mm/SongHLCXN19}{
						CNN + TextCNN
					}{}{Y}{Y}{Y}{}{Y}
					\rsrow{DBLP:conf/www/YinL0019}{
						Triplet Network
					}{}{}{Y}{}{}{}
				\bottomrule
				\addlinespace
				\multicolumn{9}{l}{\textit{\footnotemark[1] Purchase data, comments, ratings, reviews}}
			\end{tabularx}
		\end{table*}
	
	\subsection{Recent works}
		Approaches from recent literature on clothing and fashion recommendation systems are explored below. They all claim to outperform state-of-the-art methods \cite{DBLP:conf/sigir/LiuWW17, DBLP:conf/icdm/KangFWM17, DBLP:conf/sigir/ChenZ0NLC17, DBLP:conf/aaai/HeM16} and present novel ideas for tackling the task.

		In \citeyear{DBLP:conf/www/YinL0019} \lithead{DBLP:conf/www/YinL0019}{
			propose a knowledge learning method that uses both visual compatibility relationships and style information. They also acknowledge that AUC alone as a metric of performance is not enough for recommendation systems as it has the risk of only recommending popular items which have a lot of similarities and overlap even if they are not relevant to the user.
		}
		
		A model for both general compatibility and personalized preference modeling which characterizes item-item and user-item interactions is presented by \lithead{DBLP:conf/mm/SongHLCXN19}{} However, they use a simple linear fusion strategy for combining general compatibility and personalized preference instead of an advanced strategies like attentive fusion.
		
		\lithead{DBLP:conf/kdd/ChenHXGGSLPZZ19}{
			use a transformer to propose a Personalized Outfit Generaion model and deploys it on an industrial-scale application. But since it operates on a commercial platform, it is more susceptible to the cold-start problem as newer items and users get added.
		}
		
		A framework is proposed by \lithead{DBLP:conf/aaai/YangMLWC19}{
			which places items in a unified embedding space where category complementary relations are encoded as vector translations. However, such embeddings need more exploration of fine-grained relations beyond just category-level co-occurrence to include rules based on color, texture, style, etc.
		}
		
		In \citeyear{DBLP:journals/corr/abs-2005-06584} \lithead{DBLP:journals/corr/abs-2005-06584}{
			suggest the use of a relational network to develop new compatibility learning models to move past limitations associated with considering entire outfits, and
		} \lithead{DBLP:conf/sigir/LiW0CXC20}{
			jointly train fashion compatibility and personalized outfit recommendations for optimal results using graph networks.
		} However, neither of these approaches consider personal preferences and can improve further by using multi-modal inputs and incorporating them into the graph network.
		
		\lithead{9156794}{
			propose an embedding to identify garments that are compatible with user's body shape and demonstrate how to learn the embedding from catalog images of models of various shapes and sizes wearing fashion items. They use the SMPL \cite{SMPL:2015} model to describe the body attributes.
		}
		
		A multi-modal framework is presented by \lithead{DBLP:journals/ijon/SunHWZP20}{
			which uses both semantic and visual embeddings for a unified deep learning model.
		} \lithead{DBLP:conf/sigir/DongWSDN20}{
			propose TryOnCM, another multi-modal try-on-guided compatibility modeling scheme to learn compatibility via the try-on appearance of outfit rather than individual items.
		}

		\lithead{9156535}{
			demonstrate a scalable approach via category-based subspace attention networks, and introduce an outfit ranking loss function to better model item relationships in an entire outfit.
		}
	
		In \citeyear{DBLP:conf/iccvw/KimSMSSP21} \lithead{DBLP:conf/iccvw/KimSMSSP21}{
			present a self-supervised learning framework that can learn color and texture-aware features without labeling, thus being better suited for transfer learning. But it assumes similar colors and textures are compatible and does not explore complementary nature of differently colored or textured items.
		} \lithead{DBLP:journals/tomccap/YangSFWDN21}{
			propose an attribute-wise explainable fashion compatibility model using representation learning. Although it uses general user preferences from dataset, it does not consider specific user preference while querying, leading to results which are not personalized.
		}
		
		In \citeyear{9775146}, as a successor to TryOnCM \cite{DBLP:conf/sigir/DongWSDN20}, \lithead[TryonCM2]{9775146}{
			is presented, treating outfits as a sequence of items and using a Bi-LSTM to capture latent interaction between items. But the na√Øve method used to derive local contents by making vertical strips of the try-on outfit image instead of a robust segmentation or other spatial models causes the implementation to suffer.
		}
		
		An outfit generation framework is proposed by \lithead{9893574}{
			which uses a semantic alignment module and a collocation classification module. However, computational complexity for outfit of size N items is $O(N)$ as the framework needs $(N - 1)$ item generators to synthesize complementary fashion items.
		}

		\lithead{9857004}{
			present a framework that learns compatibility of entire outfits modeled as unordered sets using self-attention. But it does not consider multi-dimensional image features and only relies on gross features and categorical text descriptions to guide the process.
		}

		In \citeyear{DBLP:journals/eswa/BalimO23} \lithead{DBLP:journals/eswa/BalimO23}{
			present a new dataset with clothing images and user comments on compatibility, and use this to train a compatibility suggestion text generator. This does not however, evaluate a compatibility score, and only provides simplistic textual feedback of whether outfit is compatible or not.
		}

		\lithead{10049142}{
			combine a categorical dynamic graph convolutional network with multi-layered visual outputs and surrounding contextual information to obtain better fashion characteristics.
		}

		And finally, \lithead{DBLP:journals/eswa/MoZPW23}{
			pose personalized outfit compatibility as a multi-label classification problem and use two transformers to discover correlation between visual image features, fashion and physical attributes. The downside to this being an imbalance of fashion-item attribute distribution and outfit physical-label distribution which makes the multi-label classification task challenging.
		}